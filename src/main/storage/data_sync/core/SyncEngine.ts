import { DatabaseManager } from './DatabaseManager'
import { ApiClient } from './ApiClient'
import { logger } from '../utils/logger'
import { ChangeRecord, ServerChangeLog, SyncResponse } from '../models/SyncTypes'
import { syncConfig } from '../config/sync.config'
import { Semaphore } from '../utils/semaphore'
import { getEncryptionService } from '../services/EncryptionRegistry'
import { decryptPayload, encryptPayload } from '../utils/combinedEncryption'

export class SyncEngine {
  constructor(
    private db: DatabaseManager,
    private api: ApiClient
  ) {}

  async incrementalSync(tableName: string): Promise<SyncResponse> {
    const pending = this.db.getPendingChanges().filter((c) => c.table_name === tableName)
    if (pending.length === 0) {
      return { success: true, message: 'æ— å¾…åŒæ­¥å˜æ›´', synced_count: 0, failed_count: 0 }
    }

    // åˆ†æ‰¹
    const batches: ChangeRecord[][] = []
    for (let i = 0; i < pending.length; i += syncConfig.batchSize) {
      batches.push(pending.slice(i, i + syncConfig.batchSize))
    }

    const semaphore = new Semaphore(syncConfig.maxConcurrentBatches)
    let totalSynced = 0
    let totalFailed = 0

    await Promise.all(
      batches.map(async (batch) => {
        const release = await semaphore.acquire()
        try {
          const data = await Promise.all(
            batch.map((b) => this.prepareRecordForUpload(tableName, { ...b.change_data, operation_type: b.operation_type }))
          )
          const res = await this.withRetry(() => this.api.incrementalSync(tableName, data))

          const conflictUUIDs = new Set((res.conflicts || []).map((c) => c.uuid))
          const conflictIds = batch.filter((b) => conflictUUIDs.has(b.record_uuid)).map((b) => b.id)
          const successIds = batch.filter((b) => !conflictUUIDs.has(b.record_uuid)).map((b) => b.id)

          // æ ‡è®°çŠ¶æ€
          this.db.markChangesSynced(successIds)
          if (conflictIds.length > 0) {
            const reason = (res.conflicts || []).map((c) => `${c.uuid}:${c.reason}`).join(',')
            this.db.markChangesConflict(conflictIds, reason)
          }

          // å¯¹æˆåŠŸçš„ UPDATE è®°å½•ï¼Œæœ¬åœ°è‡ªå¢ versionï¼ˆå‡å°‘å†æ¬¡å†²çªçª—å£ï¼‰
          for (const b of batch) {
            if (!conflictUUIDs.has(b.record_uuid) && b.operation_type === 'UPDATE') {
              const current = b.change_data?.version
              if (typeof current === 'number' && current > 0) {
                this.db.bumpVersion(tableName, b.record_uuid, current)
              }
            }
          }

          totalSynced += successIds.length
          totalFailed += conflictIds.length
        } catch (e: any) {
          logger.error('æ‰¹æ¬¡ä¸Šä¼ å¤±è´¥', e?.message)
          totalFailed += batch.length
        } finally {
          release()
        }
      })
    )

    return { success: totalFailed === 0, message: 'å¢é‡åŒæ­¥å®Œæˆ', synced_count: totalSynced, failed_count: totalFailed }
  }

  /**
   * æ™ºèƒ½å¢é‡åŒæ­¥ - æ ¹æ®æ•°æ®é‡è‡ªåŠ¨é€‰æ‹©åˆ†é¡µæˆ–æ‰¹é‡æ¨¡å¼
   */
  async incrementalSyncSmart(tableName: string): Promise<SyncResponse> {
    const totalChanges = this.db.getTotalPendingChangesCount(tableName)

    // å°æ•°æ®é‡ï¼šä½¿ç”¨ç°æœ‰æ‰¹é‡æ–¹æ³•
    if (totalChanges <= 1000) {
      return await this.incrementalSync(tableName)
    }

    // å¤§æ•°æ®é‡ï¼šä½¿ç”¨åˆ†é¡µå¤„ç†
    return await this.incrementalSyncPaged(tableName)
  }

  /**
   * åˆ†é¡µå¢é‡åŒæ­¥ - å¤„ç†å¤§æ•°æ®é‡åœºæ™¯
   */
  private async incrementalSyncPaged(tableName: string): Promise<SyncResponse> {
    const pageSize = 500
    let offset = 0
    let totalSynced = 0
    let totalFailed = 0
    let currentPage = 1

    const totalChanges = this.db.getTotalPendingChangesCount(tableName)
    const totalPages = Math.ceil(totalChanges / pageSize)

    while (offset < totalChanges) {
      const pageChanges = this.db.getPendingChangesPage(tableName, pageSize, offset)
      if (pageChanges.length === 0) break

      try {
        // ä½¿ç”¨ç°æœ‰çš„æ‰¹å¤„ç†é€»è¾‘
        const result = await this.processBatchChanges(tableName, pageChanges)
        totalSynced += result.synced_count || 0
        totalFailed += result.failed_count || 0
      } catch (error) {
        logger.error(`ç¬¬ ${currentPage} é¡µå¤„ç†å¤±è´¥:`, error)
        totalFailed += pageChanges.length
      }

      offset += pageSize
      currentPage++

      // å°å»¶è¿Ÿï¼Œé¿å…è¿‡åº¦å ç”¨èµ„æº
      await new Promise((resolve) => setTimeout(resolve, 100))
    }

    const message = `åˆ†é¡µå¢é‡åŒæ­¥å®Œæˆ: ${totalPages} é¡µï¼ŒæˆåŠŸ ${totalSynced}ï¼Œå¤±è´¥ ${totalFailed}`

    return {
      success: totalFailed === 0,
      message,
      synced_count: totalSynced,
      failed_count: totalFailed
    }
  }

  /**
   * å¤„ç†ä¸€æ‰¹å˜æ›´è®°å½•
   */
  private async processBatchChanges(tableName: string, changes: ChangeRecord[]): Promise<SyncResponse> {
    const semaphore = new Semaphore(syncConfig.maxConcurrentBatches)
    let batchSynced = 0
    let batchFailed = 0

    // å°†é¡µé¢æ•°æ®å†åˆ†æˆå°æ‰¹æ¬¡
    const batches: ChangeRecord[][] = []
    for (let i = 0; i < changes.length; i += syncConfig.batchSize) {
      batches.push(changes.slice(i, i + syncConfig.batchSize))
    }

    await Promise.all(
      batches.map(async (batch) => {
        const release = await semaphore.acquire()
        try {
          const data = await Promise.all(
            batch.map((b) => this.prepareRecordForUpload(tableName, { ...b.change_data, operation_type: b.operation_type }))
          )
          const res = await this.withRetry(() => this.api.incrementalSync(tableName, data))

          const conflictUUIDs = new Set((res.conflicts || []).map((c) => c.uuid))
          const conflictIds = batch.filter((b) => conflictUUIDs.has(b.record_uuid)).map((b) => b.id)
          const successIds = batch.filter((b) => !conflictUUIDs.has(b.record_uuid)).map((b) => b.id)

          // æ ‡è®°çŠ¶æ€
          this.db.markChangesSynced(successIds)
          if (conflictIds.length > 0) {
            const reason = (res.conflicts || []).map((c) => `${c.uuid}:${c.reason}`).join(',')
            this.db.markChangesConflict(conflictIds, reason)
          }

          batchSynced += successIds.length
          batchFailed += conflictIds.length
        } catch (e: any) {
          logger.error('æ‰¹æ¬¡ä¸Šä¼ å¤±è´¥', e?.message)
          batchFailed += batch.length
        } finally {
          release()
        }
      })
    )

    return {
      success: batchFailed === 0,
      message: 'æ‰¹æ¬¡å¤„ç†å®Œæˆ',
      synced_count: batchSynced,
      failed_count: batchFailed
    }
  }

  private async withRetry<T>(fn: () => Promise<T>, attempts = 3, baseDelay = 500): Promise<T> {
    let lastErr: any
    for (let i = 0; i < attempts; i++) {
      try {
        return await fn()
      } catch (e) {
        lastErr = e
        const delay = Math.min(10000, baseDelay * Math.pow(2, i))
        await new Promise((res) => setTimeout(res, delay))
      }
    }
    throw lastErr
  }

  async downloadAndApplyCloudChanges(): Promise<{ applied: number; lastSeq: number }> {
    let since = this.db.getLastSequenceId()
    let applied = 0
    let lastSeq = since

    // å¼€å¯è¿œç«¯åº”ç”¨å®ˆå«ï¼ŒæŠ‘åˆ¶è§¦å‘å™¨å†™å…¥change_log
    this.db.setRemoteApplyGuard(true)
    try {
      let hasMore = true
      while (hasMore) {
        const { changes, hasMore: nextHasMore, lastSequenceId } = await this.api.getChanges(since, syncConfig.batchSize)
        if (!changes || changes.length === 0) {
          hasMore = false
          break
        }

        for (const ch of changes) {
          await this.applySingleChange(ch)
          applied += 1
          lastSeq = Math.max(lastSeq, ch.sequence_id)
        }

        this.db.setLastSequenceId(lastSeq)
        hasMore = !!nextHasMore
        if (hasMore) {
          since = lastSequenceId
        }
      }
    } finally {
      this.db.setRemoteApplyGuard(false)
    }

    logger.info(`ä¸‹è½½å¹¶åº”ç”¨äº‘ç«¯å˜æ›´å®Œæˆ: ${applied} æ¡, lastSeq=${lastSeq}`)
    return { applied, lastSeq }
  }

  async fullSyncAndApply(tableName: string): Promise<number> {
    // å…¨é‡æ‹‰å–å¹¶åº”ç”¨ï¼Œé»˜è®¤æŒ‰ INSERT æ–¹å¼ upsert
    this.db.setRemoteApplyGuard(true)
    try {
      const res = await this.api.fullSync(tableName)
      const list = res.data || []
      let applied = 0
      for (const raw of list) {
        const data = await this.maybeDecryptChange(tableName, raw)
        if (tableName === 't_assets_sync') {
          this.applyToAssets('INSERT', data)
        } else if (tableName === 't_asset_chains_sync') {
          this.applyToAssetChains('INSERT', data)
        }
        applied += 1
      }
      logger.info(`å…¨é‡åŒæ­¥åº”ç”¨å®Œæˆ: ${tableName} å…± ${applied} æ¡`)
      return applied
    } finally {
      this.db.setRemoteApplyGuard(false)
    }
  }

  private async applySingleChange(ch: ServerChangeLog) {
    const raw = ch.change_data ? JSON.parse(ch.change_data) : {}
    const baseTable = ch.target_table.startsWith('t_assets_sync')
      ? 't_assets_sync'
      : ch.target_table.startsWith('t_asset_chains_sync')
        ? 't_asset_chains_sync'
        : ch.target_table
    const data = await this.maybeDecryptChange(baseTable, raw)
    if (ch.target_table.startsWith('t_assets_sync')) {
      this.applyToAssets(ch.operation_type, data)
    } else if (ch.target_table.startsWith('t_asset_chains_sync')) {
      this.applyToAssetChains(ch.operation_type, data)
    }
  }

  private async maybeDecryptChange(tableName: string, data: any): Promise<any> {
    if (!data) return data

    // ğŸ” æ·»åŠ è§£å¯†å‰çš„è¯¦ç»†æ—¥å¿—
    logger.info('==== è§£å¯†è°ƒè¯•ä¿¡æ¯ ====')
    logger.info('è¡¨å:', tableName)
    logger.info('åŸå§‹æ•°æ®ç±»å‹:', typeof data)
    logger.info('åŸå§‹æ•°æ®é”®:', Object.keys(data))
    logger.info('data_cipher_text å­˜åœ¨:', 'data_cipher_text' in data)
    logger.info('data_cipher_text ç±»å‹:', typeof data.data_cipher_text)
    logger.info('data_cipher_text å€¼:', data.data_cipher_text)
    logger.info('å®Œæ•´åŸå§‹æ•°æ®:', JSON.stringify(data, null, 2))

    try {
      const service = getEncryptionService()
      logger.info('åŠ å¯†æœåŠ¡çŠ¶æ€:', service ? 'å·²è·å–' : 'æœªè·å–')

      if (tableName === 't_assets_sync') {
        const cipher: string | undefined = typeof data.data_cipher_text === 'string' ? data.data_cipher_text : undefined
        logger.info('t_assets_sync è§£å¯†æ£€æŸ¥:')
        logger.info('  cipher å­˜åœ¨:', !!cipher)
        logger.info('  cipher é•¿åº¦:', cipher?.length || 0)
        logger.info('  cipher å‰50å­—ç¬¦:', cipher?.substring(0, 50))

        if (cipher) {
          logger.info('å¼€å§‹è§£å¯† t_assets_sync æ•°æ®...')
          const sensitive = await decryptPayload(cipher, service)
          logger.info('è§£å¯†ç»“æœ:', sensitive)
          logger.info('è§£å¯†ç»“æœç±»å‹:', typeof sensitive)
          logger.info('è§£å¯†ç»“æœé”®:', sensitive ? Object.keys(sensitive) : 'null')

          if (sensitive && sensitive.password !== undefined) {
            data.password = sensitive.password
            logger.info('å·²è®¾ç½® password å­—æ®µ')
          }
          if (sensitive && sensitive.username !== undefined) {
            data.username = sensitive.username
            logger.info('å·²è®¾ç½® username å­—æ®µ')
          }
        }
      } else if (tableName === 't_asset_chains_sync') {
        const cipher: string | undefined = typeof data.data_cipher_text === 'string' ? data.data_cipher_text : undefined
        logger.info('t_asset_chains_sync è§£å¯†æ£€æŸ¥:')
        logger.info('  cipher å­˜åœ¨:', !!cipher)
        logger.info('  cipher é•¿åº¦:', cipher?.length || 0)
        logger.info('  cipher å‰50å­—ç¬¦:', cipher?.substring(0, 50))

        if (cipher) {
          logger.info('å¼€å§‹è§£å¯† t_asset_chains_sync æ•°æ®...')
          const sensitive = await decryptPayload(cipher, service)
          logger.info('è§£å¯†ç»“æœ:', sensitive)
          logger.info('è§£å¯†ç»“æœç±»å‹:', typeof sensitive)
          logger.info('è§£å¯†ç»“æœé”®:', sensitive ? Object.keys(sensitive) : 'null')

          if (sensitive.chain_private_key !== undefined) {
            data.chain_private_key = sensitive.chain_private_key
            logger.info('å·²è®¾ç½® chain_private_key å­—æ®µ')
          }
          if (sensitive.passphrase !== undefined) {
            data.passphrase = sensitive.passphrase
            logger.info('å·²è®¾ç½® passphrase å­—æ®µ')
          }
        }
      }
      if ('data_cipher_text' in data) {
        delete data.data_cipher_text
      }

      // ä¿®å¤ï¼šæ ¹æ®è¡¨åè¿‡æ»¤å­—æ®µï¼Œåªä¿ç•™å¯¹åº”è¡¨çš„å­—æ®µ
      data = this.filterFieldsByTable(tableName, data)

      logger.info('è§£å¯†åçš„æœ€ç»ˆæ•°æ®:', JSON.stringify(data, null, 2))
      logger.info('==== è§£å¯†è°ƒè¯•ä¿¡æ¯ç»“æŸ ====')
    } catch (e) {
      logger.warn('æ–°æ ¼å¼å¯†æ–‡è§£å¯†å¤±è´¥ï¼ŒæŒ‰åŸæ ·åº”ç”¨', e)
      logger.error('è§£å¯†å¼‚å¸¸è¯¦æƒ…:', {
        error: e,
        message: e instanceof Error ? e.message : String(e),
        stack: e instanceof Error ? e.stack : undefined
      })
    }

    return data
  }

  /**
   * æ ¹æ®è¡¨åè¿‡æ»¤å­—æ®µï¼Œåªä¿ç•™å¯¹åº”è¡¨çš„å­—æ®µ
   * @param tableName è¡¨å
   * @param data æ•°æ®å¯¹è±¡
   * @returns è¿‡æ»¤åçš„æ•°æ®å¯¹è±¡
   */
  private filterFieldsByTable(tableName: string, data: any): any {
    if (!data || typeof data !== 'object') return data

    // å®šä¹‰å„è¡¨çš„æœ‰æ•ˆå­—æ®µ
    const tableFields = {
      t_assets_sync: [
        'uuid',
        'label',
        'asset_ip',
        'group_name',
        'auth_type',
        'port',
        'username',
        'password',
        'key_chain_id',
        'favorite',
        'asset_type',
        'created_at',
        'updated_at',
        'version'
      ],
      t_asset_chains_sync: [
        'key_chain_id',
        'uuid',
        'chain_name',
        'chain_type',
        'chain_public_key',
        'chain_private_key',
        'passphrase',
        'created_at',
        'updated_at',
        'version'
      ]
    }

    const validFields = tableFields[tableName as keyof typeof tableFields]
    if (!validFields) {
      logger.warn(`æœªçŸ¥çš„è¡¨å: ${tableName}ï¼Œè¿”å›åŸå§‹æ•°æ®`)
      return data
    }

    // åªä¿ç•™æœ‰æ•ˆå­—æ®µ
    const filteredData: any = {}
    validFields.forEach((field) => {
      if (field in data) {
        filteredData[field] = data[field]
      }
    })

    logger.info(`å­—æ®µè¿‡æ»¤å®Œæˆ (${tableName}):`)
    logger.info(`  åŸå§‹å­—æ®µ: [${Object.keys(data).join(', ')}]`)
    logger.info(`  ä¿ç•™å­—æ®µ: [${Object.keys(filteredData).join(', ')}]`)

    return filteredData
  }

  private async prepareRecordForUpload(tableName: string, record: any): Promise<any> {
    try {
      const service = getEncryptionService()
      if (tableName === 't_assets_sync') {
        const sensitive: any = {}
        if (record.password !== undefined && record.password !== null) sensitive.password = record.password
        if (record.username !== undefined && record.username !== null) sensitive.username = record.username
        if (Object.keys(sensitive).length > 0) {
          try {
            const combined = await encryptPayload(sensitive, service)
            const { password, username, ...rest } = record
            return { ...rest, data_cipher_text: combined }
          } catch {
            // å¦‚æœæ•æ„Ÿå­—æ®µå­˜åœ¨ä½†åŠ å¯†å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯ä»¥é˜²æ­¢æ˜æ–‡ä¸Šè¡Œ
            throw new Error('Failed to encrypt sensitive fields for t_assets_sync')
          }
        }
      } else if (tableName === 't_asset_chains_sync') {
        const sensitive: any = {}
        if (record.chain_private_key !== undefined && record.chain_private_key !== null) sensitive.chain_private_key = record.chain_private_key
        if (record.passphrase !== undefined && record.passphrase !== null) sensitive.passphrase = record.passphrase
        if (Object.keys(sensitive).length > 0) {
          try {
            const combined = await encryptPayload(sensitive, service)
            const { chain_private_key, passphrase, ...rest } = record
            return { ...rest, data_cipher_text: combined }
          } catch {
            // å¦‚æœæ•æ„Ÿå­—æ®µå­˜åœ¨ä½†åŠ å¯†å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯ä»¥é˜²æ­¢æ˜æ–‡ä¸Šè¡Œ
            throw new Error('Failed to encrypt sensitive fields for t_asset_chains_sync')
          }
        }
      }
    } catch (e) {
      // åŠ å¯†æˆ–æœåŠ¡è·å–å¤±è´¥éƒ½åº”è¯¥ä¸­æ–­åŒæ­¥ï¼Œé˜²æ­¢æ˜æ–‡å¤–æ³„
      throw e instanceof Error ? e : new Error(String(e))
    }
    // åç«¯å·²æ”¯æŒåŸå§‹æ•°æ®æ ¼å¼ï¼Œæ— éœ€æ ‡å‡†åŒ–
    return record
  }

  private applyToAssets(op: string, data: any) {
    if (!data) return
    switch (op) {
      case 'INSERT':
      case 'UPDATE':
        this.db.upsertAsset({
          uuid: data.uuid,
          label: data.label,
          asset_ip: data.asset_ip,
          group_name: data.group_name,
          auth_type: data.auth_type,
          port: data.port,
          username: data.username,
          password: data.password,
          key_chain_id: data.key_chain_id ?? undefined,
          favorite: !!data.favorite,
          asset_type: data.asset_type,
          created_at: data.created_at ?? new Date().toISOString(),
          updated_at: data.updated_at ?? new Date().toISOString(),
          version: typeof data.version === 'number' ? data.version : 1
        } as any)
        break
      case 'DELETE':
        if (data?.uuid) this.db.deleteAssetByUUID(data.uuid)
        break
    }
  }

  private applyToAssetChains(op: string, data: any) {
    if (!data) return
    switch (op) {
      case 'INSERT':
      case 'UPDATE':
        this.db.upsertAssetChain({
          key_chain_id: data.key_chain_id,
          uuid: data.uuid,
          chain_name: data.chain_name,
          chain_type: data.chain_type,
          chain_private_key: data.chain_private_key,
          chain_public_key: data.chain_public_key,
          passphrase: data.passphrase,
          created_at: data.created_at ?? new Date().toISOString(),
          updated_at: data.updated_at ?? new Date().toISOString(),
          version: typeof data.version === 'number' ? data.version : 1
        } as any)
        break
      case 'DELETE':
        if (data?.uuid) this.db.deleteAssetChainByUUID(data.uuid)
        break
    }
  }
}
